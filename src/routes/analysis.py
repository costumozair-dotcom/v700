#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Analysis Routes com Controles de Sess√£o - FIXED
Rotas para an√°lise de mercado com pausar/continuar/salvar
"""

import logging
from flask import Blueprint, request, jsonify, render_template
from datetime import datetime
import json
import os
from services.ultra_detailed_analysis_engine import ultra_detailed_analysis_engine
from services.auto_save_manager import auto_save_manager, salvar_etapa, salvar_erro
from services.super_orchestrator import super_orchestrator # Import the Super Orchestrator
import asyncio # Import asyncio for running async functions


logger = logging.getLogger(__name__)

analysis_bp = Blueprint('analysis', __name__)

# Instancia o Super Orchestrator
orchestrator = super_orchestrator

# Armazena sess√µes ativas
active_sessions = {}

@analysis_bp.route('/')
def index():
    """Interface principal"""
    return render_template('unified_interface.html')

@analysis_bp.route('/analyze', methods=['POST'])
@analysis_bp.route('/api/analyze', methods=['POST'])
def analyze():
    """Inicia an√°lise de mercado com controle de sess√£o"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({'error': 'Dados n√£o fornecidos'}), 400

        logger.info("üöÄ Iniciando an√°lise de mercado ultra-detalhada")

        # Cria sess√£o √∫nica
        session_id = auto_save_manager.iniciar_sessao()

        # Salva dados da requisi√ß√£o
        salvar_etapa("requisicao_analise", data, categoria="analise_completa")

        segmento_negocio = data.get('segmento')
        produto_servico = data.get('produto')
        publico_alvo = data.get('publico_alvo', '')
        objetivos_estrategicos = data.get('objetivos_estrategicos', '')
        contexto_adicional = data.get('contexto_adicional', '')

        logger.info(f"üìä Dados recebidos: Segmento={segmento_negocio}, Produto={produto_servico}")

        # Prepara query de pesquisa
        query = data.get('query', f"mercado de {produto_servico or segmento_negocio} no brasil desde 2022")
        logger.info(f"üîç Query de pesquisa: {query}")

        # Salva query
        salvar_etapa("query_preparada", {"query": query}, categoria="pesquisa_web")

        # Registra sess√£o como ativa
        active_sessions[session_id] = {
            'status': 'running',
            'data': data,
            'started_at': datetime.now().isoformat(),
            'paused_at': None
        }

        # Fun√ß√£o para enviar atualiza√ß√µes de progresso
        def send_progress_update(session_id, step, message):
            logger.info(f"Progress {session_id}: Step {step} - {message}")
            salvar_etapa("progresso", {
                "step": step,
                "message": message,
                "timestamp": datetime.now().isoformat()
            }, categoria="logs")

        # Executa an√°lise COMPLETA com todos os servi√ßos - S√ì DADOS REAIS
        logger.info("üöÄ Executando an√°lise COMPLETA com TODOS os servi√ßos - ZERO SIMULADOS")

        analysis_data = {
            'segmento': segmento_negocio,
            'produto': produto_servico,
            'publico': publico_alvo,
            'objetivos': objetivos_estrategicos,
            'contexto': contexto_adicional,
            'query': query,
            'session_id': session_id,
            'validation_mode': 'REAL_DATA_ONLY'
        }

        # VALIDA√á√ÉO CR√çTICA: Verifica se dados essenciais est√£o preenchidos
        if not segmento_negocio or not produto_servico:
            return jsonify({
                'success': False,
                'error': 'FALHA CR√çTICA: Segmento e Produto s√£o obrigat√≥rios para an√°lise com dados reais',
                'session_id': session_id
            }), 400

        resultado = super_orchestrator.execute_synchronized_analysis(
            data=analysis_data,
            session_id=session_id,
            progress_callback=lambda step, msg: send_progress_update(session_id, step, msg)
        )

        # VALIDA√á√ÉO CR√çTICA: Verifica se o resultado cont√©m dados reais
        data_validation = resultado.get('data_validation', {})
        if not resultado.get('success', False):
            logger.error(f"‚ùå FALHA na an√°lise: {resultado.get('error', 'Erro desconhecido')}")
            return jsonify({
                'success': False,
                'error': f"Falha na an√°lise: {resultado.get('error', 'Erro desconhecido')}",
                'session_id': session_id,
                'partial_data': resultado
            }), 500

        


        # Atualiza status da sess√£o
        active_sessions[session_id]['status'] = 'completed'
        active_sessions[session_id]['completed_at'] = datetime.now().isoformat()

        return jsonify({
            'success': True,
            'session_id': session_id,
            'message': 'An√°lise COMPLETA conclu√≠da com sucesso!',
            'processing_time': resultado.get('metadata', {}).get('processing_time_formatted', 'N/A'),
            'data': resultado
        })

    except Exception as e:
        logger.error(f"‚ùå Erro na an√°lise: {str(e)}")
        if 'session_id' in locals() and session_id:
            active_sessions[session_id]['status'] = 'error'
            active_sessions[session_id]['error'] = str(e)
            active_sessions[session_id]['error_at'] = datetime.now().isoformat()
            salvar_erro("erro_analise", e)
        else:
            salvar_erro("erro_geral_analise", e)
        return jsonify({
            'success': False,
            'session_id': locals().get('session_id'), # Try to get session_id if it was created
            'error': str(e),
            'message': 'Erro na an√°lise. Dados intermedi√°rios foram salvos.'
        }), 500


@analysis_bp.route('/sessions', methods=['GET'])
def list_sessions():
    """Lista todas as sess√µes salvas"""
    try:
        # Lista sess√µes do auto_save_manager
        try:
            saved_sessions_ids = auto_save_manager.listar_sessoes()
        except AttributeError:
            # Fallback se m√©todo n√£o existe
            import os
            base_path = 'relatorios_intermediarios/logs'
            saved_sessions_ids = []
            if os.path.exists(base_path):
                for item in os.listdir(base_path):
                    if item.startswith('session_'):
                        saved_sessions_ids.append(item.replace('session_', '').split('.')[0]) # Extract session ID
            else:
                saved_sessions_ids = []

        sessions_list = []
        for session_id in saved_sessions_ids:
            session_data = active_sessions.get(session_id, {})
            session_info = auto_save_manager.obter_info_sessao(session_id)

            sessions_list.append({
                'session_id': session_id,
                'status': session_data.get('status', 'saved'), # Default to 'saved' if not active
                'segmento': session_data.get('data', {}).get('segmento', 'N/A'),
                'produto': session_data.get('data', {}).get('produto', 'N/A'), # Corrected variable name here
                'started_at': session_data.get('started_at'),
                'completed_at': session_data.get('completed_at'),
                'paused_at': session_data.get('paused_at'),
                'error': session_data.get('error'),
                'etapas_salvas': len(session_info.get('etapas', {})) if session_info else 0
            })

        return jsonify({
            'success': True,
            'sessions': sessions_list,
            'total': len(sessions_list)
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao listar sess√µes: {str(e)}")
        return jsonify({'error': str(e)}), 500

@analysis_bp.route('/sessions/<session_id>/pause', methods=['POST'])
def pause_session(session_id):
    """Pausa uma sess√£o ativa"""
    try:
        if session_id not in active_sessions:
            return jsonify({'error': 'Sess√£o n√£o encontrada'}), 404

        session = active_sessions[session_id]
        if session['status'] != 'running':
            return jsonify({'error': 'Sess√£o n√£o est√° em execu√ß√£o'}), 400

        # Atualiza status
        session['status'] = 'paused'
        session['paused_at'] = datetime.now().isoformat()

        # Salva estado de pausa
        salvar_etapa("sessao_pausada", {
            "session_id": session_id,
            "paused_at": session['paused_at'],
            "reason": "User requested pause"
        }, categoria="logs")

        logger.info(f"‚è∏Ô∏è Sess√£o {session_id} pausada pelo usu√°rio")

        return jsonify({
            'success': True,
            'message': 'Sess√£o pausada com sucesso',
            'session_id': session_id,
            'status': 'paused'
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao pausar sess√£o: {str(e)}")
        return jsonify({'error': str(e)}), 500

@analysis_bp.route('/sessions/<session_id>/resume', methods=['POST'])
def resume_session(session_id):
    """Resume uma sess√£o pausada"""
    try:
        if session_id not in active_sessions:
            return jsonify({'error': 'Sess√£o n√£o encontrada'}), 404

        session = active_sessions[session_id]
        if session['status'] != 'paused':
            return jsonify({'error': 'Sess√£o n√£o est√° pausada'}), 400

        # Atualiza status
        session['status'] = 'running'
        session['resumed_at'] = datetime.now().isoformat()
        session['paused_at'] = None

        # Salva estado de resume
        salvar_etapa("sessao_resumida", {
            "session_id": session_id,
            "resumed_at": session['resumed_at'],
            "reason": "User requested resume"
        }, categoria="logs")

        logger.info(f"‚ñ∂Ô∏è Sess√£o {session_id} resumida pelo usu√°rio")

        return jsonify({
            'success': True,
            'message': 'Sess√£o resumida com sucesso',
            'session_id': session_id,
            'status': 'running'
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao resumir sess√£o: {str(e)}")
        return jsonify({'error': str(e)}), 500

@analysis_bp.route('/sessions/<session_id>/continue', methods=['POST'])
def continue_session(session_id):
    """Continua uma sess√£o salva - VERS√ÉO COM DEBUG COMPLETO"""
    try:
        # VALIDA√á√ÉO INICIAL
        if not session_id:
            logger.error("‚ùå Session ID n√£o fornecido")
            return jsonify({
                'success': False,
                'error': 'Session ID obrigat√≥rio'
            }), 400

        logger.info(f"üîÑ Tentando continuar an√°lise da sess√£o {session_id}...")

        # Debug: Lista todas as poss√≠veis localiza√ß√µes de dados
        possible_paths = [
            f"relatorios_intermediarios/analise_completa/{session_id}",
            f"relatorios_intermediarios/logs/{session_id}",
            f"relatorios_intermediarios/logs/session_{session_id}.json",
            f"relatorios_intermediarios/{session_id}"
        ]
        
        logger.info(f"üîç Verificando caminhos poss√≠veis para sess√£o {session_id}:")
        for path in possible_paths:
            exists = os.path.exists(path)
            logger.info(f"  - {path}: {'EXISTS' if exists else 'NOT_FOUND'}")

        # Recupera dados da sess√£o com m√∫ltiplas estrat√©gias
        session_info = None
        recovery_method = "none"
        
        # ESTRAT√âGIA 1: auto_save_manager
        try:
            session_info = auto_save_manager.obter_info_sessao(session_id)
            if session_info:
                recovery_method = "auto_save_manager"
                logger.info(f"‚úÖ M√©todo auto_save_manager: {len(session_info.get('etapas', {})) if session_info else 0} etapas")
            else:
                logger.warning("‚ö†Ô∏è auto_save_manager retornou None")
        except Exception as e:
            logger.error(f"‚ùå Erro no auto_save_manager: {e}")

        # ESTRAT√âGIA 2: Busca manual em pastas
        if not session_info:
            logger.info("üîç Tentando recupera√ß√£o manual...")
            for base_path in ["relatorios_intermediarios/analise_completa", "relatorios_intermediarios/logs", "relatorios_intermediarios"]:
                session_path = f"{base_path}/{session_id}"
                if os.path.exists(session_path):
                    logger.info(f"üìÅ Encontrada pasta: {session_path}")
                    try:
                        session_info = {'etapas': {}}
                        recovery_method = f"manual_{base_path.split('/')[-1]}"
                        
                        files = os.listdir(session_path)
                        logger.info(f"üìã Arquivos encontrados: {files}")
                        
                        for file_name in files:
                            if file_name.endswith('.json'):
                                file_path = os.path.join(session_path, file_name)
                                try:
                                    with open(file_path, 'r', encoding='utf-8') as f:
                                        file_data = json.load(f)
                                        session_info['etapas'][file_name] = file_data
                                        logger.info(f"‚úÖ Arquivo lido: {file_name} ({len(str(file_data))} chars)")
                                except Exception as fe:
                                    logger.warning(f"‚ö†Ô∏è Erro ao ler {file_name}: {fe}")
                        break
                    except Exception as e:
                        logger.error(f"‚ùå Erro na recupera√ß√£o manual de {session_path}: {e}")

        # ESTRAT√âGIA 3: Busca por arquivo √∫nico de sess√£o
        if not session_info:
            session_file_path = f"relatorios_intermediarios/logs/session_{session_id}.json"
            if os.path.exists(session_file_path):
                logger.info(f"üìÑ Encontrado arquivo de sess√£o: {session_file_path}")
                try:
                    with open(session_file_path, 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                        session_info = {'etapas': {'session_file': file_data}}
                        recovery_method = "session_file"
                        logger.info(f"‚úÖ Arquivo de sess√£o lido: {len(str(file_data))} chars")
                except Exception as e:
                    logger.error(f"‚ùå Erro ao ler arquivo de sess√£o: {e}")

        # Verifica se conseguiu recuperar alguma coisa
        if not session_info or not session_info.get('etapas'):
            logger.error(f"‚ùå Nenhum dado recuperado para sess√£o {session_id}")
            logger.error(f"üìä Debug info: session_info={session_info}, recovery_method={recovery_method}")
            
            # Lista todos os arquivos das pastas para debug
            for base_path in ["relatorios_intermediarios/analise_completa", "relatorios_intermediarios/logs"]:
                if os.path.exists(base_path):
                    try:
                        all_items = os.listdir(base_path)
                        session_items = [item for item in all_items if session_id in item]
                        logger.info(f"üîç Items relacionados √† sess√£o em {base_path}: {session_items}")
                    except Exception as e:
                        logger.error(f"‚ùå Erro ao listar {base_path}: {e}")
            
            return jsonify({
                'success': False,
                'error': f'Sess√£o {session_id} n√£o encontrada ou sem dados (method: {recovery_method})',
                'debug_info': {
                    'session_id': session_id,
                    'recovery_method': recovery_method,
                    'session_info': bool(session_info),
                    'paths_checked': possible_paths
                }
            }), 404

        logger.info(f"‚úÖ Dados recuperados usando m√©todo: {recovery_method}")
        logger.info(f"üìã Etapas dispon√≠veis: {list(session_info.get('etapas', {}).keys())}")

        # Estrat√©gias m√∫ltiplas para recuperar dados originais
        original_data = None
        data_source = "none"
        
        # Debug: mostra estrutura das etapas
        logger.info(f"üîç Analisando estrutura das etapas:")
        for etapa_nome, etapa_data in session_info.get('etapas', {}).items():
            data_type = type(etapa_data).__name__
            if isinstance(etapa_data, dict):
                keys = list(etapa_data.keys())[:5]  # Primeiras 5 chaves
                logger.info(f"  üìÑ {etapa_nome}: {data_type} com chaves: {keys}")
            else:
                logger.info(f"  üìÑ {etapa_nome}: {data_type} ({len(str(etapa_data))} chars)")
        
        # Estrat√©gia 1: Busca por arquivos de requisi√ß√£o
        for etapa_nome, etapa_data in session_info.get('etapas', {}).items():
            if 'requisicao_analise' in etapa_nome.lower() or 'requisicao' in etapa_nome.lower():
                logger.info(f"üéØ Processando arquivo de requisi√ß√£o: {etapa_nome}")
                if isinstance(etapa_data, dict):
                    # Tenta diferentes estruturas de dados
                    possible_data = [
                        etapa_data.get('dados', {}),
                        etapa_data.get('data', {}),
                        etapa_data,  # Os dados podem estar na raiz
                        etapa_data.get('request_data', {}),
                        etapa_data.get('payload', {})
                    ]
                    
                    for candidate in possible_data:
                        if isinstance(candidate, dict) and (candidate.get('segmento') or candidate.get('produto')):
                            original_data = candidate
                            data_source = f"requisicao_dict_{etapa_nome}"
                            logger.info(f"‚úÖ Dados recuperados: {list(candidate.keys())}")
                            break
                    
                    if original_data:
                        break
                        
                elif isinstance(etapa_data, str):
                    try:
                        parsed_data = json.loads(etapa_data)
                        if isinstance(parsed_data, dict):
                            possible_data = [
                                parsed_data.get('dados', {}),
                                parsed_data.get('data', {}),
                                parsed_data
                            ]
                            for candidate in possible_data:
                                if isinstance(candidate, dict) and (candidate.get('segmento') or candidate.get('produto')):
                                    original_data = candidate
                                    data_source = f"requisicao_json_{etapa_nome}"
                                    logger.info(f"‚úÖ Dados recuperados de JSON: {list(candidate.keys())}")
                                    break
                            if original_data:
                                break
                    except json.JSONDecodeError as e:
                        logger.warning(f"‚ö†Ô∏è Erro ao parsear JSON de {etapa_nome}: {e}")

        # Estrat√©gia 2: Busca em qualquer etapa que tenha dados de mercado
        if not original_data:
            logger.warning("‚ö†Ô∏è Dados de requisi√ß√£o n√£o encontrados, buscando em outras etapas...")
            for etapa_nome, etapa_data in session_info.get('etapas', {}).items():
                if isinstance(etapa_data, dict):
                    # Procura por dados que tenham segmento/produto diretamente
                    if etapa_data.get('segmento') or etapa_data.get('produto'):
                        original_data = etapa_data
                        data_source = f"etapa_direta_{etapa_nome}"
                        logger.info(f"‚úÖ Dados encontrados diretamente: {etapa_nome}")
                        break
                    
                    # Procura dentro de sub-estruturas
                    for key, value in etapa_data.items():
                        if isinstance(value, dict) and (value.get('segmento') or value.get('produto')):
                            original_data = value
                            data_source = f"sub_estrutura_{etapa_nome}.{key}"
                            logger.info(f"‚úÖ Dados encontrados em sub-estrutura: {etapa_nome}.{key}")
                            break
                    
                    if original_data:
                        break

        # Estrat√©gia 3: Busca por padr√µes alternativos de nomenclatura
        if not original_data:
            logger.info("üîç Procurando por campos alternativos...")
            alternative_fields = {
                'segmento': ['segment', 'business_segment', 'market_segment', 'categoria', 'setor'],
                'produto': ['product', 'service', 'servico', 'item', 'offering']
            }
            
            for etapa_nome, etapa_data in session_info.get('etapas', {}).items():
                if isinstance(etapa_data, dict):
                    found_fields = {}
                    
                    # Procura pelos campos alternativos
                    for standard_field, alternatives in alternative_fields.items():
                        for alt_field in [standard_field] + alternatives:
                            if etapa_data.get(alt_field):
                                found_fields[standard_field] = etapa_data[alt_field]
                                break
                    
                    if len(found_fields) >= 1:  # Pelo menos um campo encontrado
                        # Cria estrutura completa com campos encontrados
                        original_data = {
                            'segmento': found_fields.get('segmento', ''),
                            'produto': found_fields.get('produto', ''),
                            'publico_alvo': etapa_data.get('publico_alvo', etapa_data.get('target_audience', '')),
                            'objetivos_estrategicos': etapa_data.get('objetivos_estrategicos', etapa_data.get('objectives', '')),
                            'contexto_adicional': etapa_data.get('contexto_adicional', etapa_data.get('context', ''))
                        }
                        data_source = f"campos_alternativos_{etapa_nome}"
                        logger.info(f"‚úÖ Dados montados com campos alternativos: {found_fields}")
                        break

        # Estrat√©gia 4: Dados m√≠nimos com informa√ß√µes do usu√°rio
        if not original_data:
            logger.warning("‚ö†Ô∏è Tentando extrair dados do contexto da sess√£o...")
            
            # Procura por qualquer texto que possa dar pistas
            context_hints = []
            for etapa_nome, etapa_data in session_info.get('etapas', {}).items():
                if isinstance(etapa_data, dict):
                    # Procura em campos de texto
                    text_fields = ['query', 'message', 'description', 'title', 'name']
                    for field in text_fields:
                        if etapa_data.get(field):
                            context_hints.append(str(etapa_data[field]))
            
            # Tenta criar dados m√≠nimos inteligentes
            if context_hints:
                combined_context = ' '.join(context_hints)
                original_data = {
                    'segmento': 'An√°lise de Mercado Extra√≠da',
                    'produto': 'Produto/Servi√ßo da Sess√£o',
                    'publico_alvo': '',
                    'objetivos_estrategicos': '',
                    'contexto_adicional': f'Continua√ß√£o da sess√£o {session_id}. Contexto: {combined_context[:200]}...'
                }
                data_source = "contexto_extraido"
                logger.info(f"‚ö†Ô∏è Dados criados a partir do contexto: {combined_context[:100]}...")
            else:
                # √öltimo recurso: dados totalmente gen√©ricos
                original_data = {
                    'segmento': 'An√°lise de Mercado Geral',
                    'produto': 'Produto/Servi√ßo',
                    'publico_alvo': '',
                    'objetivos_estrategicos': '',
                    'contexto_adicional': f'Continua√ß√£o da sess√£o {session_id}'
                }
                data_source = "dados_genericos"
                logger.warning("‚ö†Ô∏è Usando dados completamente gen√©ricos")

        if not original_data:
            logger.error("‚ùå Falha completa na recupera√ß√£o de dados")
            return jsonify({
                'success': False,
                'error': 'N√£o foi poss√≠vel recuperar dados da sess√£o',
                'debug_info': {
                    'session_id': session_id,
                    'recovery_method': recovery_method,
                    'data_source': data_source,
                    'etapas_disponiveis': list(session_info.get('etapas', {}).keys())
                }
            }), 400

        logger.info(f"‚úÖ Dados recuperados usando fonte: {data_source}")

        # Normaliza e valida os dados recuperados
        normalized_data = {
            'segmento': str(original_data.get('segmento', '')).strip(),
            'produto': str(original_data.get('produto', '')).strip(),
            'publico_alvo': str(original_data.get('publico_alvo', original_data.get('publico', ''))).strip(),
            'objetivos_estrategicos': str(original_data.get('objetivos_estrategicos', original_data.get('objetivos', ''))).strip(),
            'contexto_adicional': str(original_data.get('contexto_adicional', original_data.get('contexto', ''))).strip()
        }

        # VALIDA√á√ÉO FLEX√çVEL: Se dados essenciais est√£o vazios, usa valores padr√£o
        validation_warnings = []
        if not normalized_data['segmento']:
            normalized_data['segmento'] = 'Mercado Geral'
            validation_warnings.append("Segmento vazio - usando valor padr√£o")
        
        if not normalized_data['produto']:
            normalized_data['produto'] = 'Produto/Servi√ßo'
            validation_warnings.append("Produto vazio - usando valor padr√£o")

        # Log completo dos dados processados
        logger.info(f"üìã Dados processados:")
        logger.info(f"  - Fonte: {data_source}")
        logger.info(f"  - Segmento: '{normalized_data['segmento']}'")
        logger.info(f"  - Produto: '{normalized_data['produto']}'")
        logger.info(f"  - P√∫blico: '{normalized_data['publico_alvo'][:50]}...' ({len(normalized_data['publico_alvo'])} chars)")
        logger.info(f"  - Avisos: {validation_warnings}")

        # VALIDA√á√ÉO FINAL CR√çTICA: Garante dados m√≠nimos v√°lidos
        if not normalized_data['segmento'] or not normalized_data['produto']:
            logger.error(f"‚ùå Dados inv√°lidos ap√≥s normaliza√ß√£o: segmento='{normalized_data['segmento']}', produto='{normalized_data['produto']}'")
            return jsonify({
                'success': False,
                'error': 'FALHA CR√çTICA: N√£o foi poss√≠vel obter dados v√°lidos para continuar an√°lise',
                'debug_info': {
                    'session_id': session_id,
                    'data_source': data_source,
                    'recovery_method': recovery_method,
                    'original_data_keys': list(original_data.keys()) if original_data else [],
                    'normalized_data': normalized_data,
                    'validation_warnings': validation_warnings
                }
            }), 400

        # Registra como sess√£o ativa
        active_sessions[session_id] = {
            'status': 'running',
            'data': normalized_data,
            'continued_at': datetime.now().isoformat(),
            'original_session': True,
            'recovery_info': {
                'method': recovery_method,
                'data_source': data_source,
                'warnings': validation_warnings
            }
        }

        # Callback de progresso melhorado
        def progress_callback(step, message):
            logger.info(f"Continue Progress {session_id}: Step {step} - {message}")
            salvar_etapa("progresso_continuacao", {
                "step": step,
                "message": message,
                "timestamp": datetime.now().isoformat(),
                "session_id": session_id,
                "recovery_info": f"{recovery_method}:{data_source}"
            }, categoria="logs")

        # Prepara dados para an√°lise
        analysis_data = {
            'segmento': normalized_data['segmento'],
            'produto': normalized_data['produto'],
            'publico': normalized_data['publico_alvo'],
            'objetivos': normalized_data['objetivos_estrategicos'],
            'contexto': normalized_data['contexto_adicional'],
            'query': original_data.get('query', f"mercado de {normalized_data['produto']} {normalized_data['segmento']} no brasil desde 2022"),
            'session_id': session_id,
            'validation_mode': 'REAL_DATA_ONLY'
        }

        logger.info(f"üöÄ INICIANDO AN√ÅLISE com dados validados:")
        logger.info(f"  üìä Segmento: {analysis_data['segmento']}")
        logger.info(f"  üè∑Ô∏è  Produto: {analysis_data['produto']}")
        logger.info(f"  üîç Query: {analysis_data['query'][:100]}...")

        # Salva tentativa de continua√ß√£o com dados completos
        salvar_etapa("tentativa_continuacao_detalhada", {
            "session_id": session_id,
            "analysis_data": analysis_data,
            "recovery_info": {
                "method": recovery_method,
                "data_source": data_source,
                "warnings": validation_warnings
            },
            "timestamp": datetime.now().isoformat()
        }, categoria="logs")

        # Executa an√°lise
        logger.info("üéØ Chamando super_orchestrator.execute_synchronized_analysis...")
        resultado = super_orchestrator.execute_synchronized_analysis(
            data=analysis_data,
            session_id=session_id,
            progress_callback=progress_callback
        )

        # Verifica resultado
        if not resultado.get('success', False):
            error_msg = resultado.get('error', 'Erro desconhecido na an√°lise')
            logger.error(f"‚ùå Falha na continua√ß√£o: {error_msg}")
            
            active_sessions[session_id]['status'] = 'error'
            active_sessions[session_id]['error'] = error_msg
            active_sessions[session_id]['error_at'] = datetime.now().isoformat()
            
            salvar_erro("erro_continuacao_analise", Exception(error_msg), {
                'session_id': session_id,
                'analysis_data': analysis_data
            })
            
            return jsonify({
                'success': False,
                'session_id': session_id,
                'error': f"Falha na continua√ß√£o da an√°lise: {error_msg}",
                'partial_data': resultado
            }), 500

        # Sucesso
        active_sessions[session_id]['status'] = 'completed'
        active_sessions[session_id]['completed_at'] = datetime.now().isoformat()

        logger.info(f"‚úÖ An√°lise da sess√£o {session_id} continuada e conclu√≠da com sucesso!")

        return jsonify({
            'success': True,
            'session_id': session_id,
            'message': 'An√°lise continuada e conclu√≠da com sucesso!',
            'processing_time': resultado.get('metadata', {}).get('processing_time_formatted', 'N/A'),
            'data': resultado
        })

    except Exception as e:
        logger.error(f"‚ùå Erro cr√≠tico ao continuar sess√£o {session_id}: {str(e)}")
        
        # Registra erro
        if session_id in active_sessions:
            active_sessions[session_id]['status'] = 'error'
            active_sessions[session_id]['error'] = str(e)
            active_sessions[session_id]['error_at'] = datetime.now().isoformat()
        
        salvar_erro("erro_critico_continuacao_sessao", e, {'session_id': session_id})
        
        return jsonify({
            'success': False,
            'session_id': session_id,
            'error': str(e),
            'message': 'Erro cr√≠tico na continua√ß√£o da an√°lise. Dados intermedi√°rios foram salvos.'
        }), 500

@analysis_bp.route('/sessions/<session_id>/save', methods=['POST'])
def save_session(session_id):
    """Salva explicitamente uma sess√£o"""
    try:
        if session_id not in active_sessions:
            return jsonify({'error': 'Sess√£o n√£o encontrada'}), 404

        session = active_sessions[session_id]

        # Salva estado completo da sess√£o
        salvar_etapa("sessao_salva_explicitamente", {
            "session_id": session_id,
            "saved_at": datetime.now().isoformat(),
            "session_data": session,
            "reason": "User explicitly saved session"
        }, categoria="logs")

        logger.info(f"üíæ Sess√£o {session_id} salva explicitamente pelo usu√°rio")

        return jsonify({
            'success': True,
            'message': 'Sess√£o salva com sucesso',
            'session_id': session_id
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao salvar sess√£o: {str(e)}")
        return jsonify({'error': str(e)}), 500

@analysis_bp.route('/sessions/<session_id>/status', methods=['GET'])
@analysis_bp.route('/api/sessions/<session_id>/status', methods=['GET'])
def get_session_status(session_id):
    """Obt√©m status de uma sess√£o"""
    try:
        session = active_sessions.get(session_id)
        session_info = auto_save_manager.obter_info_sessao(session_id)

        if not session and not session_info:
            return jsonify({'error': 'Sess√£o n√£o encontrada'}), 404

        status_data = {
            'session_id': session_id,
            'status': session.get('status', 'saved') if session else 'saved', # Default to 'saved' if not active
            'active': session is not None,
            'saved': session_info is not None,
            'etapas_salvas': len(session_info.get('etapas', {})) if session_info else 0
        }

        if session:
            status_data.update({
                'started_at': session.get('started_at'),
                'paused_at': session.get('paused_at'),
                'completed_at': session.get('completed_at'),
                'error': session.get('error'),
                'segmento': session.get('data', {}).get('segmento'),
                'produto': session.get('data', {}).get('produto')
            })

        return jsonify({
            'success': True,
            'session': status_data
        })

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter status da sess√£o: {str(e)}")
        return jsonify({'error': str(e)}), 500

@analysis_bp.route('/api/sessions', methods=['GET'])
def api_list_sessions():
    """API endpoint para listar sess√µes"""
    return list_sessions()

@analysis_bp.route('/api/progress/<session_id>', methods=['GET'])
def api_get_progress(session_id):
    """API endpoint para obter progresso"""
    try:
        session = active_sessions.get(session_id)
        session_info = auto_save_manager.obter_info_sessao(session_id)

        if not session and not session_info:
            return jsonify({'error': 'Sess√£o n√£o encontrada'}), 404

        if session and session['status'] == 'error':
            return jsonify({
                'success': False,
                'completed': False,
                'percentage': 0,
                'current_step': f"Erro: {session.get('error')}",
                'total_steps': 13,
                'estimated_time': 'N/A'
            })

        if session and session['status'] == 'completed':
            return jsonify({
                'success': True,
                'completed': True,
                'percentage': 100,
                'current_step': 'An√°lise conclu√≠da',
                'total_steps': 13,
                'estimated_time': '0m'
            })
        elif session and session['status'] == 'running':
            # Tenta obter progresso do Super Orchestrator se dispon√≠vel
            progress_data = super_orchestrator.get_session_progress(session_id)
            if progress_data:
                return jsonify({
                    'success': True,
                    'completed': progress_data.get('completed', False),
                    'percentage': progress_data.get('percentage', 0),
                    'current_step': progress_data.get('current_step', 'Processando...'),
                    'total_steps': progress_data.get('total_steps', 13),
                    'estimated_time': progress_data.get('estimated_time', 'N/A')
                })
            else:
                # Fallback para c√°lculo de progresso baseado no tempo
                start_time = datetime.fromisoformat(session['started_at'])
                elapsed = (datetime.now() - start_time).total_seconds()
                progress = min(elapsed / 600 * 100, 95)  # 10 minutos = 100% (ajustar conforme necess√°rio)

                return jsonify({
                    'success': True,
                    'completed': False,
                    'percentage': progress,
                    'current_step': f'Processando... ({progress:.0f}%)',
                    'total_steps': 13,
                    'estimated_time': f'{max(0, 10 - elapsed/60):.0f}m' # Estimativa de 10 minutos totais
                })
        else: # Paused or unknown status
            return jsonify({
                'success': True,
                'completed': False,
                'percentage': 0,
                'current_step': 'Pausado' if session and session['status'] == 'paused' else 'Aguardando',
                'total_steps': 13,
                'estimated_time': 'N/A'
            })

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter progresso: {str(e)}")
        return jsonify({'error': str(e)}), 500
